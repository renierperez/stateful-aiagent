import logging
import os
from google import genai
from google.genai import types
import json

class NewsReasoning:
    def __init__(self, model_name="gemini-1.5-flash", api_key=None):
        project_id = os.environ.get("GOOGLE_CLOUD_PROJECT")
        location = os.environ.get("GOOGLE_CLOUD_LOCATION", "us-central1")
        api_key = os.environ.get("GOOGLE_API_KEY")
        
        if api_key:
            # Use Google AI Studio
            self.client = genai.Client(api_key=api_key)
            self.model_name = os.environ.get("GOOGLE_MODEL_NAME", "gemini-2.0-flash-exp") # Default to a known working model for AI Studio
            logging.info(f"Google Gen AI SDK inicializado con AI Studio. Modelo: {self.model_name}")
        else:
            # Use Vertex AI
            if not project_id:
                logging.warning("GOOGLE_CLOUD_PROJECT no est√° configurada.")
            self.client = genai.Client(vertexai=True, project=project_id, location=location)
            self.model_name = model_name
            logging.info(f"Google Gen AI SDK inicializado con Vertex AI. Modelo: {self.model_name}")

    def generate_search_queries(self, past_summaries):
        """Genera 3 t√©rminos de b√∫squeda basados en el contexto pasado."""
        import datetime
        current_date = datetime.datetime.now().strftime("%Y-%m-%d")
        context_text = "\n".join([f"- {s['timestamp']}: {', '.join(s['topics_covered'])}" for s in past_summaries])
        
        prompt = f"""
        Eres un agente de noticias experto en Cuba. Hoy es {current_date}.
        Basado en los siguientes temas cubiertos en los √∫ltimos d√≠as:
        {context_text}
        
        Genera 3 t√©rminos de b√∫squeda (queries) para encontrar noticias nuevas.
        - **IMPORTANTE:** Solo busca noticias publicadas hoy o ayer ({current_date}).
        - Usa t√©rminos como 'hoy', '√∫ltima hora', o el a√±o actual '2025' para asegurar frescura.
        - No limites las b√∫squedas a un solo dominio usando 'site:'. Usa t√©rminos generales para obtener resultados de diversas fuentes.
        - Evita temas que ya est√©n cerrados o repetidos sin nueva informaci√≥n.
        
        Responde √∫nicamente con un objeto JSON que contenga una lista de strings llamada 'queries'.
        Ejemplo: {{"queries": ["apagones cuba hoy", "relaciones cuba estados unidos", "econom√≠a cuba 2025"]}}
        """
        
        try:
            response = self.client.models.generate_content(
                model=self.model_name,
                contents=prompt
            )
            # Basic JSON extraction from response text
            text = response.text.strip()
            if "```json" in text:
                text = text.split("```json")[1].split("```")[0].strip()
            elif "```" in text:
                text = text.split("```")[1].split("```")[0].strip()
            
            data = json.loads(text)
            queries = data.get("queries", ["actualidad Cuba hoy", "noticias Cuba √∫ltima hora", "Cuba 2025"])
            logging.info(f"Queries generadas: {queries}")
            return queries[:3]
        except Exception as e:
            logging.error(f"Error al generar queries: {e}")
            return ["actualidad Cuba hoy", "noticias Cuba √∫ltima hora", "Cuba 2025"]

    def grounded_search(self, queries):
        """Realiza b√∫squedas usando Vertex AI Grounding con Google Search."""
        all_results = []
        for query in queries:
            try:
                # Grounding with Google Search
                # Note: This requires the model to support grounding, e.g., gemini-1.5-pro or gemini-1.5-flash
                # and the client must be initialized with Vertex AI or have access to Google Search tool.
                
                # For AI Studio, grounding is not directly available via the same API yet, 
                # but we can simulate it or use the model's knowledge if it's fresh.
                # However, the user wants Vertex AI Grounding.
                
                # If using AI Studio, we might need a different approach or just rely on its fresh knowledge.
                # Given the constraints, I will implement it using the Google Search tool if available, 
                # or fallback to standard generation if not.
                
                from google.genai.types import Tool, GoogleSearch
                
                google_search_tool = Tool(google_search=GoogleSearch())
                
                response = self.client.models.generate_content(
                    model=self.model_name,
                    contents=f"Busca noticias recientes sobre: {query}. Proporciona una lista de URLs de fuentes confiables.",
                    config={
                        'tools': [google_search_tool],
                    }
                )
                
                # Extract URLs from grounding metadata or text
                # This is a bit tricky as the structure depends on the response.
                # We will look for URLs in the text as a fallback.
                import re
                urls = re.findall(r'https?://[^\s<>"]+|www\.[^\s<>"]+', response.text)
                
                for url in urls:
                    # Clean URL
                    url = url.strip().rstrip(').,')
                    if url not in [r['url'] for r in all_results]:
                        all_results.append({
                            'title': f"Resultado de Grounding para {query}",
                            'url': url,
                            'snippet': response.text[:200] # Use part of response as snippet
                        })
                
                logging.info(f"Grounding para '{query}' encontr√≥ {len(urls)} URLs.")
                
            except Exception as e:
                logging.warning(f"Grounding fall√≥ para '{query}': {e}")
                # Fallback to standard search is handled in main.py if this returns empty
        
        return all_results

    def filter_articles(self, articles, memory):
        """Filtra art√≠culos que sean sem√°nticamente redundantes usando memoria vectorial."""
        if not articles:
            return []
        
        filtered_articles = []
        for article in articles:
            title = article.get('title', '')
            snippet = article.get('snippet', '')
            
            # 1. Buscar temas similares en memoria vectorial
            similar_topics = memory.find_similar_topics(title, limit=3)
            
            if similar_topics:
                logging.info(f"Temas similares encontrados para '{title}': {similar_topics}")
                # 2. Usar LLM para decidir si es redundante basado en temas similares
                prompt = f"""
                Analiza si la siguiente noticia es redundante con respecto a los temas ya cubiertos recientemente.
                
                Temas cubiertos recientemente (similares): {', '.join(similar_topics)}
                
                Nueva noticia:
                T√≠tulo: {title}
                Resumen: {snippet}
                
                ¬øEs esta noticia nueva y aporta informaci√≥n relevante, o es repetida/redundante con los temas cubiertos?
                Responde √∫nicamente con 'NUEVA' o 'REPETIDA'.
                """
                
                try:
                    response = self.client.models.generate_content(
                        model=self.model_name,
                        contents=prompt
                    )
                    result = response.text.strip().upper()
                    if "NUEVA" in result:
                        filtered_articles.append(article)
                    else:
                        logging.info(f"Art√≠culo filtrado por redundancia sem√°ntica: {title}")
                except Exception as e:
                    logging.error(f"Error al filtrar art√≠culo: {e}")
                    filtered_articles.append(article) # Keep it if error
            else:
                # No hay temas similares, es nueva
                filtered_articles.append(article)
        
        return filtered_articles

    def summarize_articles(self, articles_data=None, past_summaries=None, economic_data=None):
        """Genera un resumen consolidado de los art√≠culos en formato HTML."""
        articles_text = ""
        if articles_data:
            for i, art in enumerate(articles_data):
                articles_text += f"--- Articulo {i+1} ---\n"
                articles_text += f"T√≠tulo: {art.get('title')}\n"
                articles_text += f"Fuente: {art.get('url')}\n"
                articles_text += f"Contenido: {art.get('text')[:2000]}\n\n" # Limit text per article
        else:
            articles_text = "No se encontraron nuevas noticias relevantes hoy."
        
        context_text = ""
        if past_summaries:
            context_text = "\n".join([f"- {s['timestamp']}: {', '.join(s['topics_covered'])}" for s in past_summaries])

        economic_section = ""
        contents = []
        
        if economic_data:
            if isinstance(economic_data, bytes):
                # Handle image data
                from google.genai import types
                img_part = types.Part.from_bytes(data=economic_data, mime_type="image/png")
                contents.append(img_part)
                economic_section = "\n[Imagen de Tasas de Cambio adjunta]\n"
            else:
                # Handle text data
                economic_section = f"\nDatos de Tasas de Cambio (El Toque):\n{economic_data[:2000]}\n"

        prompt = f"""
        Eres un periodista internacional experto en pol√≠tica y econom√≠a de Cuba.
        Crea un bolet√≠n de noticias profesional en formato HTML.
        
        Contexto de d√≠as anteriores:
        {context_text}
        
        Noticias de hoy:
        {articles_text}
        {economic_section}
        
        Instrucciones para el formato HTML (Sigue este estilo EXACTAMENTE):
        1.  **Estilo General:** Fuente sans-serif (Helvetica, Arial), fondo blanco, ancho m√°ximo 800px.
        2.  **T√≠tulo:** "üá®üá∫ Resumen Diario de Cuba" en azul oscuro, con una l√≠nea gruesa debajo.
        3.  **An√°lisis del Editor:** Un cuadro con fondo gris claro (`#f4f4f4`), bordes redondeados, texto en cursiva. T√≠tulo "An√°lisis del Editor:" en negrita.
        4.  **Noticias:** T√≠tulo "Las 5 Noticias M√°s Importantes del D√≠a" en azul. Lista numerada. Cada √≠tem con:
            - T√≠tulo en negrita.
            - Breve descripci√≥n (si hay).
            - Enlace "Leer m√°s ‚Üí" en color rojo/naranja, abriendo en nueva pesta√±a.
        5.  **Indicadores Econ√≥micos:** Si hay datos, crea una secci√≥n similar a las noticias o una tabla sencilla, antes del pie de p√°gina.
        6.  **Pie de p√°gina:** Centrado, color gris, texto "Generado por Google AI ({self.model_name}) - 2025".
        
        Contenido:
        - Si hay noticias nuevas: Analiza los hechos del d√≠a, comparando con d√≠as anteriores. Contrasta fuentes oficiales e internacionales.
        - Si NO hay noticias nuevas: Indica que la situaci√≥n se mantiene estable.
        3. **Secci√≥n de Econom√≠a (OBLIGATORIA)**: Incluye siempre una secci√≥n con las tasas de cambio, usando los datos proporcionados. Si no hay datos, indica que no est√°n disponibles hoy, pero mant√©n la secci√≥n.
        
        Usa un tono profesional, anal√≠tico y objetivo.
        
        Datos de Noticias:
        {articles_text}
        
        {economic_section}
        
        Res√∫menes Recientes (Contexto):
        {context_text}
        
        Responde √∫nicamente con un objeto JSON:
        {{
            "summary_html": "contenido HTML aqu√≠...",
            "topics": ["tema1", "tema2", "tema3"]
        }}
        """
        contents.append(prompt)
        
        try:
            response = self.client.models.generate_content(
                model=self.model_name,
                contents=contents
            )
            text = response.text.strip()
            if "```json" in text:
                text = text.split("```json")[1].split("```")[0].strip()
            elif "```" in text:
                text = text.split("```")[1].split("```")[0].strip()
            
            data = json.loads(text)
            return data.get("summary_html", ""), data.get("topics", [])
        except Exception as e:
            logging.error(f"Error al resumir: {e}")
            return "Error al generar el resumen.", []
